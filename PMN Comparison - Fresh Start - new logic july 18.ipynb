{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a681e597-6495-43c8-8a2e-6d8c03680877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new file\n",
    "df_master = pd.read_excel(\"pmn_master july 15 2025.xlsx\")\n",
    "df_transitions = pd.read_excel(\"Master Transition Planner.xlsx\")\n",
    "df_overview = pd.read_excel(\"Method Overview Dictionary.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6135da8-36cf-4dab-b652-31e7b8457e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9546f38dbb7e4d33a495c517aaba047d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='From Series:', options=(\"Alfred's Basic Piano Library\", 'B‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, FileLink\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "# Load spreadsheet\n",
    "df = pd.read_excel(\"pmn_master july 15 2025.xlsx\")\n",
    "\n",
    "# Clean and prepare data\n",
    "df.rename(columns={\n",
    "    'Series': 'series',\n",
    "    'Book Title': 'book_title',\n",
    "    'Book Order': 'book_order',\n",
    "    'Concept': 'concept',\n",
    "    'Intro Type': 'intro_type',\n",
    "    'Review Status': 'review_status'\n",
    "}, inplace=True)\n",
    "\n",
    "df['concept'] = df['concept'].astype(str).str.strip().str.lower()\n",
    "df['book_title'] = df['book_title'].astype(str).str.strip()\n",
    "df.sort_values(by=['series', 'book_order'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "weights_dict = df.groupby('concept')['Weight'].max().to_dict()\n",
    "\n",
    "def build_summary_widget(df):\n",
    "    nonlocal_export_filename = {\"name\": \"comparison_results.xlsx\"}\n",
    "    download_output = widgets.Output()\n",
    "    series_list = sorted(df['series'].unique())\n",
    "    from_series_dropdown = widgets.Dropdown(options=series_list, description='From Series:')\n",
    "    from_book_dropdown = widgets.Dropdown(description='From Book:')\n",
    "    output = widgets.Output()\n",
    "    download_button = widgets.Button(description=\"Download Excel\", button_style='success', disabled=True)\n",
    "    excel_data = io.BytesIO()\n",
    "\n",
    "    def update_from_books(*args):\n",
    "        series = from_series_dropdown.value\n",
    "        books = df[df['series'] == series][['book_order', 'book_title']].drop_duplicates().sort_values('book_order')\n",
    "        from_book_dropdown.options = [\n",
    "            (f\"{int(row.book_order)} ‚Äì {row.book_title}\", row.book_order)\n",
    "            for row in books.itertuples(index=False)\n",
    "        ]\n",
    "\n",
    "    from_series_dropdown.observe(update_from_books, names='value')\n",
    "    update_from_books()\n",
    "\n",
    "    def on_compare_clicked(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            from_series = from_series_dropdown.value\n",
    "            from_book = from_book_dropdown.value\n",
    "\n",
    "            from_book_title = df.loc[\n",
    "                (df['series'] == from_series) & (df['book_order'] == from_book),\n",
    "                'book_title'\n",
    "            ].values[0]\n",
    "\n",
    "            from_label = f\"{from_series} - {from_book_title}\"\n",
    "            date_str = datetime.today().strftime('%B %d %Y')\n",
    "            export_filename = f\"Comparison - {from_label} - {date_str}.xlsx\".replace('/', '-')\n",
    "            nonlocal_export_filename[\"name\"] = export_filename\n",
    "\n",
    "            current_concepts = set(df[(df['series'] == from_series) & (df['book_order'] <= from_book)]['concept'])\n",
    "\n",
    "            summary_data = []\n",
    "\n",
    "            for to_series in series_list:\n",
    "                if to_series == from_series:\n",
    "                    continue\n",
    "            \n",
    "                to_books = df[df['series'] == to_series]['book_order'].unique()\n",
    "                for to_book in to_books:\n",
    "                    to_df = df[(df['series'] == to_series) & (df['book_order'] == to_book)]\n",
    "                    earlier_df = df[(df['series'] == to_series) & (df['book_order'] < to_book)]\n",
    "                    to_title = to_df['book_title'].iloc[0] if not to_df.empty else ''\n",
    "            \n",
    "                    to_book_set = set(to_df['concept'])\n",
    "                    to_earlier_set = set(earlier_df['concept'])\n",
    "            \n",
    "                    repeated = current_concepts & to_book_set\n",
    "                    new = to_book_set - current_concepts\n",
    "                    missing = to_earlier_set - current_concepts\n",
    "            \n",
    "                    def get_weighted_total(concepts):\n",
    "                        return sum(weights_dict.get(c, 0.25) for c in concepts)\n",
    "            \n",
    "                    total_weight = get_weighted_total(to_book_set) or 1.0\n",
    "            \n",
    "                    repeated_weighted = get_weighted_total(repeated)\n",
    "                    new_weighted = get_weighted_total(new)\n",
    "            \n",
    "                    pct_repeated_weighted = round(repeated_weighted / total_weight * 100, 1) if total_weight else 0\n",
    "                    pct_new_weighted = round(new_weighted / total_weight * 100, 1) if total_weight else 0\n",
    "            \n",
    "                    def sort_by_weight(concepts):\n",
    "                        return sorted(concepts, key=lambda c: weights_dict.get(c, 0.25), reverse=True)\n",
    "            \n",
    "                    summary_data.append({\n",
    "                        'To Series': to_series,\n",
    "                        'To Book': to_book,\n",
    "                        'To Book Title': to_title,\n",
    "                        '% Repeated (Weighted)': pct_repeated_weighted,\n",
    "                        '% New (Weighted)': pct_new_weighted,\n",
    "                        '# Missing': len(missing),\n",
    "                        'Repeated Concepts': \", \".join(sort_by_weight(repeated)),\n",
    "                        'New Concepts': \", \".join(sort_by_weight(new)),\n",
    "                        'Missing Concepts': \", \".join(sort_by_weight(missing)),\n",
    "                    })\n",
    "\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            \n",
    "\n",
    "            # ----------- Natural Progression -----------\n",
    "            next_books = df[(df['series'] == from_series) & (df['book_order'] > from_book)]\n",
    "            if not next_books.empty:\n",
    "                next_book_order = next_books['book_order'].min()\n",
    "                next_book_df = df[(df['series'] == from_series) & (df['book_order'] == next_book_order)]\n",
    "\n",
    "                next_concepts = set(next_book_df['concept'])\n",
    "                repeated_np = current_concepts & next_concepts\n",
    "                new_np = next_concepts - current_concepts\n",
    "\n",
    "                repeated_np_count = len(repeated_np)\n",
    "                new_np_count = len(new_np)\n",
    "                total_np = repeated_np_count + new_np_count\n",
    "\n",
    "                repeated_np_pct = round(repeated_np_count / total_np * 100) if total_np else 0\n",
    "                new_np_pct = round(new_np_count / total_np * 100) if total_np else 0\n",
    "\n",
    "                print(\"\\nNatural Progression (Same Series ‚Üí Next Book):\")\n",
    "                print(f\"  Repeated: {repeated_np_count} concepts ({repeated_np_pct}%)\")\n",
    "                print(f\"  New: {new_np_count} concepts ({new_np_pct}%)\")\n",
    "\n",
    "            display(summary_df)\n",
    "\n",
    "            # ----------- Excel Export -----------\n",
    "            excel_data.seek(0)\n",
    "            excel_data.truncate()\n",
    "            \n",
    "            # Convert % columns to decimal fractions (e.g., 86 ‚Üí 0.86)\n",
    "            for col in summary_df.columns:\n",
    "                if '%' in col:\n",
    "                    summary_df[col] = summary_df[col] / 100\n",
    "            \n",
    "            with pd.ExcelWriter(excel_data, engine='xlsxwriter') as writer:\n",
    "                workbook = writer.book\n",
    "                percent_fmt = workbook.add_format({'num_format': '0%'})\n",
    "                green_fmt = workbook.add_format({'bg_color': '#C6EFCE'})\n",
    "                yellow_fmt = workbook.add_format({'bg_color': '#FFF2CC'})\n",
    "                green_percent_fmt = workbook.add_format({'num_format': '0%', 'bg_color': '#C6EFCE'})\n",
    "                yellow_percent_fmt = workbook.add_format({'num_format': '0%', 'bg_color': '#FFF2CC'})\n",
    "            \n",
    "                # Write comparison data to main sheet\n",
    "                summary_df.to_excel(writer, index=False, sheet_name='Comparison')\n",
    "                worksheet = writer.sheets['Comparison']\n",
    "            \n",
    "                for i, col in enumerate(summary_df.columns):\n",
    "                    max_len = max(\n",
    "                        summary_df[col].astype(str).map(len).max(),\n",
    "                        len(str(col))\n",
    "                    ) + 2\n",
    "            \n",
    "                    is_percent = '%' in col\n",
    "                    is_weighted = 'Weighted' in col\n",
    "                    is_unweighted = 'Unweighted' in col\n",
    "            \n",
    "                    if is_percent and is_weighted:\n",
    "                        worksheet.set_column(i, i, max_len, green_percent_fmt)\n",
    "                    elif is_percent and is_unweighted:\n",
    "                        worksheet.set_column(i, i, max_len, yellow_percent_fmt)\n",
    "                    elif is_weighted:\n",
    "                        worksheet.set_column(i, i, max_len, green_fmt)\n",
    "                    elif is_unweighted:\n",
    "                        worksheet.set_column(i, i, max_len, yellow_fmt)\n",
    "                    else:\n",
    "                        worksheet.set_column(i, i, max_len)\n",
    "            \n",
    "                # Write natural progression data (if exists)\n",
    "                if 'repeated_np_count' in locals() and 'new_np_count' in locals():\n",
    "                    natural_df = pd.DataFrame([{\n",
    "                        'Next Book (Same Series)': next_book_df['book_title'].iloc[0],\n",
    "                        '# Repeated': repeated_np_count,\n",
    "                        '% Repeated': repeated_np_pct / 100,\n",
    "                        '# New': new_np_count,\n",
    "                        '% New': new_np_pct / 100\n",
    "                    }])\n",
    "                    natural_df.to_excel(writer, index=False, sheet_name='Natural Progression')\n",
    "                    np_sheet = writer.sheets['Natural Progression']\n",
    "            \n",
    "                    for i, col in enumerate(natural_df.columns):\n",
    "                        max_len = max(\n",
    "                            natural_df[col].astype(str).map(len).max(),\n",
    "                            len(str(col))\n",
    "                        ) + 2\n",
    "            \n",
    "                        if '%' in col:\n",
    "                            np_sheet.set_column(i, i, max_len, percent_fmt)\n",
    "                        else:\n",
    "                            np_sheet.set_column(i, i, max_len)\n",
    "\n",
    "\n",
    "\n",
    "            download_button.disabled = False\n",
    "\n",
    "    def on_download_clicked(b):\n",
    "        filepath = nonlocal_export_filename[\"name\"]\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(excel_data.getvalue())\n",
    "        with download_output:\n",
    "            clear_output()\n",
    "            display(FileLink(filepath, result_html_prefix=\"ÔøΩÔøΩ Click to download: \"))\n",
    "\n",
    "    compare_button = widgets.Button(description=\"Compare\", button_style='primary')\n",
    "    compare_button.on_click(on_compare_clicked)\n",
    "\n",
    "    download_button.on_click(on_download_clicked)\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([from_series_dropdown, from_book_dropdown]),\n",
    "        compare_button,\n",
    "        download_button,\n",
    "        download_output,\n",
    "        output\n",
    "    ])\n",
    "\n",
    "    display(ui)\n",
    "\n",
    "# Run it\n",
    "build_summary_widget(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c6750a-5072-4c8c-a001-edaed0ce3cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and creating WORKING widget...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689e8a0c9e7047a5a74b97b3c5ea2324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Current Series:', layout=Layout(width='300px'), options=(\"‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copy this entire code block into a new cell in your Jupyter notebook\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from ipywidgets import Dropdown, Button, VBox, HBox, Output, Checkbox, HTML, Accordion\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel(\"pmn_master july 15 2025.xlsx\")\n",
    "\n",
    "# Clean and prepare data\n",
    "df.rename(columns={\n",
    "    'Series': 'series',\n",
    "    'Book Title': 'book_title',\n",
    "    'Book Order': 'book_order',\n",
    "    'Concept': 'concept',\n",
    "    'Intro Type': 'intro_type',\n",
    "    'Review Status': 'review_status'\n",
    "}, inplace=True)\n",
    "\n",
    "df['concept'] = df['concept'].astype(str).str.strip().str.lower()\n",
    "df['book_title'] = df['book_title'].astype(str).str.strip()\n",
    "df.sort_values(by=['series', 'book_order'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "weights_dict = df.groupby('concept')['Weight'].max().to_dict()\n",
    "\n",
    "def compare_books_cumulative_fixed(df, current_series, current_book_order, new_series, new_book_order, include_reviews=True):\n",
    "    \"\"\"\n",
    "    Updated logic for Widget 2 (drilldown):\n",
    "    - from_set: all concepts in current_series up to and including current_book_order\n",
    "    - to_book_set: only concepts in new_series, new_book_order\n",
    "    - to_earlier_set: all concepts in new_series, book_order < new_book_order\n",
    "    - repeated = from_set & to_book_set\n",
    "    - new = to_book_set - from_set\n",
    "    - missing = to_earlier_set - from_set\n",
    "    - Percentages: weighted, denominator is total weight of to_book_set (repeated + new)\n",
    "    - Missing: raw count\n",
    "    \"\"\"\n",
    "    from_set = set(df[(df['series'] == current_series) & (df['book_order'] <= current_book_order)]['concept'])\n",
    "    to_book_set = set(df[(df['series'] == new_series) & (df['book_order'] == new_book_order)]['concept'])\n",
    "    to_earlier_set = set(df[(df['series'] == new_series) & (df['book_order'] < new_book_order)]['concept'])\n",
    "\n",
    "    repeated = from_set & to_book_set\n",
    "    new = to_book_set - from_set\n",
    "    missing = to_earlier_set - from_set\n",
    "\n",
    "    def get_weighted_total(concepts):\n",
    "        return sum(weights_dict.get(c, 0.25) for c in concepts)\n",
    "\n",
    "    total_weight = get_weighted_total(to_book_set) or 1.0\n",
    "    repeated_weighted = get_weighted_total(repeated)\n",
    "    new_weighted = get_weighted_total(new)\n",
    "\n",
    "    pct_repeated_weighted = round(repeated_weighted / total_weight * 100, 1) if total_weight else 0\n",
    "    pct_new_weighted = round(new_weighted / total_weight * 100, 1) if total_weight else 0\n",
    "\n",
    "    def get_details(concepts, series, book_order):\n",
    "        subset = df[(df['series'] == series) & (df['book_order'] <= book_order)]\n",
    "        details = {}\n",
    "        for concept in concepts:\n",
    "            match = subset[subset['concept'] == concept]\n",
    "            if not match.empty:\n",
    "                row = match.iloc[0]\n",
    "                details[concept] = {\n",
    "                    'book_title': row['book_title'],\n",
    "                    'page': row.get('Page', 'N/A'),\n",
    "                    'intro_type': row.get('intro_type', 'N/A'),\n",
    "                    'review_status': row.get('review_status', 'N/A')\n",
    "                }\n",
    "        return details\n",
    "\n",
    "    repeated_d = get_details(repeated, new_series, new_book_order)\n",
    "    new_d = get_details(new, new_series, new_book_order)\n",
    "    missing_d = get_details(missing, new_series, new_book_order - 1)\n",
    "\n",
    "    def sort_by_weight(concepts):\n",
    "        return sorted(concepts, key=lambda c: weights_dict.get(c, 0.25), reverse=True)\n",
    "\n",
    "    return {\n",
    "        'repeated': repeated_d,\n",
    "        'new': new_d,\n",
    "        'missing': missing_d,\n",
    "        'percentages': {\n",
    "            'repeated_count': len(repeated),\n",
    "            'new_count': len(new),\n",
    "            'missing_count': len(missing),\n",
    "            'repeated_pct_weighted': pct_repeated_weighted,\n",
    "            'new_pct_weighted': pct_new_weighted,\n",
    "            'total_weight': total_weight\n",
    "        },\n",
    "        'lists': {\n",
    "            'repeated': sort_by_weight(repeated),\n",
    "            'new': sort_by_weight(new),\n",
    "            'missing': sort_by_weight(missing)\n",
    "        }\n",
    "    }\n",
    "       \n",
    "    \n",
    "    repeated_d = get_details(repeated, new_series, new_book_order)\n",
    "    new_d = get_details(new, new_series, new_book_order)\n",
    "    missing_d = get_details(missing, new_series, new_book_order - 1)\n",
    "    \n",
    "    total = len(repeated | new | missing)\n",
    "    pct = lambda x: round((x / total) * 100, 1) if total > 0 else 0\n",
    "    \n",
    "    # Calculate weighted values\n",
    "    def get_weighted_total(concepts):\n",
    "        return sum(weights_dict.get(c, 0.25) for c in concepts)\n",
    "    \n",
    "    total_weight = get_weighted_total(repeated | new | missing) or 1.0\n",
    "    repeated_weighted = get_weighted_total(repeated)\n",
    "    new_weighted = get_weighted_total(new)\n",
    "    missing_weighted = get_weighted_total(missing)\n",
    "    \n",
    "    pct_repeated_weighted = round(repeated_weighted / total_weight * 100) if total_weight > 0 else 0\n",
    "    pct_new_weighted = round(new_weighted / total_weight * 100) if total_weight > 0 else 0\n",
    "    pct_missing_weighted = round(missing_weighted / total_weight * 100) if total_weight > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'repeated': repeated_d,\n",
    "        'new': new_d,\n",
    "        'missing': missing_d,\n",
    "        'percentages': {\n",
    "            'repeated_count': len(repeated),\n",
    "            'new_count': len(new),\n",
    "            'missing_count': len(missing),\n",
    "            'repeated_pct': pct(len(repeated)),\n",
    "            'new_pct': pct(len(new)),\n",
    "            'missing_pct': pct(len(missing)),\n",
    "            'total_concepts': total,\n",
    "            # Add weighted percentages\n",
    "            'repeated_weighted': repeated_weighted,\n",
    "            'new_weighted': new_weighted,\n",
    "            'missing_weighted': missing_weighted,\n",
    "            'repeated_pct_weighted': pct_repeated_weighted,\n",
    "            'new_pct_weighted': pct_new_weighted,\n",
    "            'missing_pct_weighted': pct_missing_weighted,\n",
    "            'total_weight': total_weight\n",
    "        }\n",
    "    }\n",
    "\n",
    "def build_working_widget(df, weights_dict):\n",
    "    \"\"\"\n",
    "    WORKING WIDGET - Simple, reliable approach\n",
    "    \"\"\"\n",
    "    \n",
    "    series_options = sorted(df['series'].unique())\n",
    "    \n",
    "    def get_book_options(series):\n",
    "        if not series:\n",
    "            return []\n",
    "        books = df[df['series'] == series][['book_order', 'book_title']].drop_duplicates().sort_values('book_order')\n",
    "        return [(f\"{int(row.book_order)} ‚Äì {row.book_title}\", int(row.book_order)) for row in books.itertuples(index=False)]\n",
    "    \n",
    "    # Create widgets\n",
    "    current_series_dd = Dropdown(\n",
    "        options=series_options, \n",
    "        value=series_options[0] if series_options else None,\n",
    "        description='Current Series:', \n",
    "        layout={'width': '300px'}\n",
    "    )\n",
    "    \n",
    "    new_series_dd = Dropdown(\n",
    "        options=series_options, \n",
    "        value=series_options[1] if len(series_options) > 1 else series_options[0] if series_options else None,\n",
    "        description='New Series:', \n",
    "        layout={'width': '300px'}\n",
    "    )\n",
    "    \n",
    "    # Initialize book dropdowns\n",
    "    current_book_options = get_book_options(series_options[0] if series_options else None)\n",
    "    current_book_dd = Dropdown(\n",
    "        options=current_book_options,\n",
    "        value=current_book_options[0][1] if current_book_options else None,\n",
    "        description='Current Book:', \n",
    "        layout={'width': '300px'}\n",
    "    )\n",
    "    \n",
    "    new_book_options = get_book_options(series_options[1] if len(series_options) > 1 else series_options[0] if series_options else None)\n",
    "    new_book_dd = Dropdown(\n",
    "        options=new_book_options,\n",
    "        value=new_book_options[0][1] if new_book_options else None,\n",
    "        description='New Book:', \n",
    "        layout={'width': '300px'}\n",
    "    )\n",
    "    \n",
    "    output = Output()\n",
    "    \n",
    "    def update_current_books(change):\n",
    "        if change['new']:\n",
    "            books = get_book_options(change['new'])\n",
    "            if books:\n",
    "                current_book_dd.options = books\n",
    "                current_book_dd.value = books[0][1]\n",
    "            else:\n",
    "                current_book_dd.options = []\n",
    "                current_book_dd.value = None\n",
    "    \n",
    "    def update_new_books(change):\n",
    "        if change['new']:\n",
    "            books = get_book_options(change['new'])\n",
    "            if books:\n",
    "                new_book_dd.options = books\n",
    "                new_book_dd.value = books[0][1]\n",
    "            else:\n",
    "                new_book_dd.options = []\n",
    "                new_book_dd.value = None\n",
    "    \n",
    "    # Attach observers\n",
    "    current_series_dd.observe(update_current_books, names='value')\n",
    "    new_series_dd.observe(update_new_books, names='value')\n",
    "    \n",
    "    def run_drilldown(*args):\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            print(f\"Running drilldown with: {current_series_dd.value}, {current_book_dd.value}, {new_series_dd.value}, {new_book_dd.value}\")\n",
    "            \n",
    "            if not all([current_series_dd.value, current_book_dd.value, \n",
    "                       new_series_dd.value, new_book_dd.value]):\n",
    "                print(\"Please select all series and books.\")\n",
    "                return\n",
    "            \n",
    "            result = compare_books_cumulative_fixed(\n",
    "                df,\n",
    "                current_series_dd.value,\n",
    "                current_book_dd.value,\n",
    "                new_series_dd.value,\n",
    "                new_book_dd.value\n",
    "            )\n",
    "            \n",
    "            checkboxes = {'Repeated': [], 'New': [], 'Missing': []}\n",
    "            concept_details = {'Repeated': result['repeated'], 'New': result['new'], 'Missing': result['missing']}\n",
    "            \n",
    "            # Generate checkbox groups with concepts sorted by weight (highest first)\n",
    "            for group_name in ['Repeated', 'New', 'Missing']:\n",
    "                # Get concepts and their weights for this group\n",
    "                group_concepts = list(concept_details[group_name].keys())\n",
    "                \n",
    "                # Sort concepts by weight (highest first)\n",
    "                def get_concept_weight(concept):\n",
    "                    return weights_dict.get(concept, 0.25)\n",
    "                \n",
    "                sorted_concepts = sorted(group_concepts, key=get_concept_weight, reverse=True)\n",
    "                \n",
    "                # Create checkboxes in weight order\n",
    "                for concept in sorted_concepts:\n",
    "                    details = concept_details[group_name][concept]\n",
    "                    weight = get_concept_weight(concept)\n",
    "                    label = f\"{concept} (weight: {weight:.2f}, {details.get('intro_type', '')}, {details.get('review_status', '')})\"\n",
    "                    cb = Checkbox(value=True, description=label, indent=False)\n",
    "                    checkboxes[group_name].append(cb)\n",
    "            \n",
    "            percentage_html = HTML()\n",
    "            \n",
    "            def update_percentages(change=None):\n",
    "                # Only include Repeated and New in the denominator\n",
    "                included = {\n",
    "                    group: [cb for cb in checkboxes[group] if cb.value]\n",
    "                    for group in ['Repeated', 'New', 'Missing']\n",
    "                }\n",
    "                # Unweighted denominator: only repeated + new\n",
    "                total = len(included['Repeated']) + len(included['New'])\n",
    "                pct = lambda x: round((len(x) / total) * 100, 1) if total else 0\n",
    "            \n",
    "                # Weighted denominator: only repeated + new\n",
    "                def get_weighted_total(concepts):\n",
    "                    return sum(weights_dict.get(c, 0.25) for c in concepts)\n",
    "            \n",
    "                included_repeated = [cb.description.split(' (weight:')[0] for cb in included['Repeated']]\n",
    "                included_new = [cb.description.split(' (weight:')[0] for cb in included['New']]\n",
    "                included_missing = [cb.description.split(' (weight:')[0] for cb in included['Missing']]\n",
    "            \n",
    "                total_weight = get_weighted_total(included_repeated + included_new) or 1.0\n",
    "                pct_weighted = lambda concepts: round((get_weighted_total(concepts) / total_weight) * 100, 1) if total_weight > 0 else 0\n",
    "            \n",
    "                percentage_html.value = (\n",
    "                    f\"<b>Updated Totals:</b><br>\"\n",
    "                    f\"‚úÖ Repeated: {len(included['Repeated'])} ({pct(included['Repeated'])}%) - Weighted: {pct_weighted(included_repeated)}%<br>\"\n",
    "                    f\"üÜï New: {len(included['New'])} ({pct(included['New'])}%) - Weighted: {pct_weighted(included_new)}%<br>\"\n",
    "                    f\"‚ùå Missing: {len(included['Missing'])} (count only, not included in %)\"\n",
    "                )\n",
    "            \n",
    "            for group in ['Repeated', 'New', 'Missing']:\n",
    "                for cb in checkboxes[group]:\n",
    "                    cb.observe(update_percentages, names='value')\n",
    "            \n",
    "            update_percentages()\n",
    "            \n",
    "            accordion = Accordion(children=[\n",
    "                VBox(checkboxes['Repeated']),\n",
    "                VBox(checkboxes['New']),\n",
    "                VBox(checkboxes['Missing'])\n",
    "            ])\n",
    "            accordion.set_title(0, f\"‚úÖ Repeated ({len(checkboxes['Repeated'])} - {result['percentages']['repeated_pct_weighted']:.1f}% weighted)\")\n",
    "            accordion.set_title(1, f\"üÜï New ({len(checkboxes['New'])} - {result['percentages']['new_pct_weighted']:.1f}% weighted)\")\n",
    "            accordion.set_title(2, f\"‚ùå Missing ({len(checkboxes['Missing'])})\")\n",
    "            \n",
    "            display(HTML(\n",
    "                f\"<b>From:</b> {current_series_dd.value}, Book {current_book_dd.value}<br>\"\n",
    "                f\"<b>To:</b> {new_series_dd.value}, Book {new_book_dd.value}<br><br>\"\n",
    "                f\"<b>Summary:</b><br>\"\n",
    "                f\"Weighted - Repeated: {result['percentages']['repeated_count']} ({result['percentages']['repeated_pct_weighted']}%), \"\n",
    "                f\"New: {result['percentages']['new_count']} ({result['percentages']['new_pct_weighted']}%)<br>\"\n",
    "                f\"Missing: {result['percentages']['missing_count']}<br><br>\"\n",
    "        \n",
    "            ))\n",
    "            display(percentage_html)\n",
    "            display(accordion)\n",
    "    \n",
    "    compare_btn = Button(description=\"Run Drilldown\", button_style='success')\n",
    "    compare_btn.on_click(run_drilldown)\n",
    "    \n",
    "    # Create the main widget container\n",
    "    ui = VBox([\n",
    "        HBox([current_series_dd, current_book_dd]),\n",
    "        HBox([new_series_dd, new_book_dd]),\n",
    "        compare_btn,\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    display(ui)\n",
    "\n",
    "# Run the working widget\n",
    "print(\"Loading data and creating WORKING widget...\")\n",
    "build_working_widget(df, weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da70feb-2bee-4511-a374-91f95e6a4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "def build_structured_concept_explorer(df):\n",
    "    all_concepts = sorted(df['concept'].unique())\n",
    "\n",
    "    concept_selector = widgets.SelectMultiple(\n",
    "        options=all_concepts,\n",
    "        description='Concepts:',\n",
    "        layout=widgets.Layout(width='500px', height='300px')\n",
    "    )\n",
    "\n",
    "    run_button = widgets.Button(description=\"Explore\", button_style='info')\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def run_explorer(*args):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            selected = list(concept_selector.value)\n",
    "            if not selected:\n",
    "                print(\"Please select one or more concepts.\")\n",
    "                return\n",
    "\n",
    "            filtered = df[df['concept'].isin(selected)].copy()\n",
    "\n",
    "            if 'Page' in filtered.columns:\n",
    "                filtered['page'] = filtered['Page']\n",
    "            else:\n",
    "                filtered['page'] = 'N/A'\n",
    "\n",
    "            def format_concept(row):\n",
    "                concept_name = row['concept']\n",
    "                intro_type = str(row.get('intro_type', '')).lower()\n",
    "                review_status = str(row.get('review_status', '')).lower()\n",
    "                if intro_type == 'informal':\n",
    "                    annotation = f\" (informal, {review_status})\"\n",
    "                    return concept_name + annotation\n",
    "                return concept_name\n",
    "\n",
    "            filtered['concept_label'] = filtered.apply(format_concept, axis=1)\n",
    "\n",
    "            group = (\n",
    "                filtered.groupby(['series', 'book_order', 'Page'])['concept_label']\n",
    "                .apply(lambda x: ', '.join(sorted(set(x))))\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            pivot = group.pivot_table(\n",
    "                index=['book_order', 'Page'],\n",
    "                columns='series',\n",
    "                values='concept_label',\n",
    "                aggfunc='first',\n",
    "                fill_value=\"\"\n",
    "            ).reset_index()\n",
    "\n",
    "            display(pivot)\n",
    "\n",
    "            # ---- Updated: Multi-Series Unique/Missing Concept Summary Table ----\n",
    "            series_list = [col for col in pivot.columns if col not in ['book_order', 'Page']]\n",
    "            summary_rows = []\n",
    "\n",
    "            for series in series_list:\n",
    "                # Concepts in this series\n",
    "                this_concepts = set(filtered[filtered['series'] == series]['concept'])\n",
    "\n",
    "                # Concepts in all *other* series\n",
    "                other_concepts = set(filtered[filtered['series'].isin([s for s in series_list if s != series])]['concept'])\n",
    "\n",
    "                unique_concepts = sorted(this_concepts - other_concepts)\n",
    "                missing_concepts = sorted(other_concepts - this_concepts)\n",
    "\n",
    "                summary_rows.append({\n",
    "                      'Series': series,\n",
    "                    'Unique Concepts (Selected)': \", \".join(unique_concepts),\n",
    "                    'Missing Concepts (Selected)': \", \".join(missing_concepts),\n",
    "                })\n",
    "\n",
    "            summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "            print(\"\\nConcept Coverage Summary:\")\n",
    "            display(summary_df)\n",
    "            # ---- Export Both Tables as Downloadable CSVs ----\n",
    "            # Pivot Table\n",
    "            csv_buffer_pivot = io.StringIO()\n",
    "            pivot.to_csv(csv_buffer_pivot, index=False)\n",
    "            b64_pivot = base64.b64encode(csv_buffer_pivot.getvalue().encode()).decode()\n",
    "            href_pivot = f'<a download=\"concept_explorer_output.csv\" href=\"data:text/csv;base64,{b64_pivot}\" target=\"_blank\">‚¨áÔ∏è Download Concept Explorer Table</a>'\n",
    "\n",
    "            # Summary Table\n",
    "            csv_buffer_summary = io.StringIO()\n",
    "            summary_df.to_csv(csv_buffer_summary, index=False)\n",
    "            b64_summary = base64.b64encode(csv_buffer_summary.getvalue().encode()).decode()\n",
    "            href_summary = f'<a download=\"concept_coverage_summary.csv\" href=\"data:text/csv;base64,{b64_summary}\" target=\"_blank\">‚¨áÔ∏è Download Concept Coverage Summary</a>'\n",
    "\n",
    "            # Display both\n",
    "            display(HTML(f\"{href_pivot}<br>{href_summary}\"))\n",
    "            # ---------------------------------------------------\n",
    "\n",
    "\n",
    "    run_button.on_click(run_explorer)\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        concept_selector,\n",
    "        run_button,\n",
    "        output\n",
    "    ])\n",
    "    display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469b00b6-259c-42bb-a271-1832a97d77c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e875e7d00cf4ff2b8fb85b2db25413b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(SelectMultiple(description='Concepts:', layout=Layout(height='300px', width='500px'), options=(‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "build_structured_concept_explorer(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97020fb6-630d-4912-ba7b-6eeca36c29e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9988fa175b344508bfe0d296603c0eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='Master Transition Planner.xlsx', description='Transition File:', lay‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, FileLink\n",
    "import io\n",
    "import json\n",
    "\n",
    "# --- File selectors (text, not upload) ---\n",
    "transition_file = widgets.Text(\n",
    "    value=\"Master Transition Planner.xlsx\",\n",
    "    description=\"Transition File:\",\n",
    "    layout=widgets.Layout(width=\"400px\")\n",
    ")\n",
    "overview_file = widgets.Text(\n",
    "    value=\"Method Overview Dictionary.xlsx\",\n",
    "    description=\"Overview File:\",\n",
    "    layout=widgets.Layout(width=\"400px\")\n",
    ")\n",
    "run_button = widgets.Button(description=\"Run Transition Analysis\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "download_output = widgets.Output()\n",
    "\n",
    "# --- Load PMN master (already in directory) ---\n",
    "df_master = pd.read_excel(\"pmn_master july 15 2025.xlsx\")\n",
    "df_master.rename(columns={\n",
    "    'Series': 'series',\n",
    "    'Book Title': 'book_title',\n",
    "    'Book Order': 'book_order',\n",
    "    'Concept': 'concept',\n",
    "    'Weight': 'weight'\n",
    "}, inplace=True)\n",
    "df_master['concept'] = df_master['concept'].astype(str).str.strip().str.lower()\n",
    "df_master['book_title'] = df_master['book_title'].astype(str).str.strip()\n",
    "df_master.sort_values(by=['series', 'book_order'], inplace=True)\n",
    "df_master.reset_index(drop=True, inplace=True)\n",
    "weights_dict = df_master.groupby('concept')['weight'].max().to_dict()\n",
    "\n",
    "# --- Helper for reading approach ---\n",
    "def get_reading_approach(series, overview_df):\n",
    "    if 'Series' not in overview_df.columns:\n",
    "        return \"\"\n",
    "    row = overview_df[overview_df['Series'].str.strip().str.lower() == str(series).strip().lower()]\n",
    "    if not row.empty:\n",
    "        return row.iloc[0]['Reading Approach']\n",
    "    return \"\"\n",
    "\n",
    "# --- Store the latest result globally for download ---\n",
    "latest_df_result = {}\n",
    "\n",
    "# --- Main logic ---\n",
    "def run_transition_analysis(b):\n",
    "    global latest_df_result\n",
    "    with output:\n",
    "        clear_output()\n",
    "        try:\n",
    "            df_transitions = pd.read_excel(transition_file.value)\n",
    "            df_overview = pd.read_excel(overview_file.value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading files: {e}\")\n",
    "            return\n",
    "\n",
    "        # Clean up column names (remove leading/trailing spaces)\n",
    "        df_transitions.columns = [col.strip() for col in df_transitions.columns]\n",
    "        df_overview.columns = [col.strip() for col in df_overview.columns]\n",
    "\n",
    "        results = []\n",
    "        for idx, row in df_transitions.iterrows():\n",
    "            from_series = row['From Series']\n",
    "            from_book = row['From Book Order']\n",
    "            to_series = row['To Series']\n",
    "            to_book_title = str(row['To Book']).strip()\n",
    "\n",
    "            # Look up the book order for the to_book_title in the master file\n",
    "            to_book_row = df_master[\n",
    "                (df_master['series'] == to_series) &\n",
    "                (df_master['book_title'].str.strip() == to_book_title)\n",
    "            ]\n",
    "            if not to_book_row.empty:\n",
    "                to_book_order = to_book_row.iloc[0]['book_order']\n",
    "            else:\n",
    "                continue  # Skip this row silently if not found\n",
    "\n",
    "            # Build sets\n",
    "            from_set = set(df_master[\n",
    "                (df_master['series'] == from_series) &\n",
    "                (df_master['book_order'] <= from_book)\n",
    "            ]['concept'])\n",
    "            to_book_set = set(df_master[\n",
    "                (df_master['series'] == to_series) &\n",
    "                (df_master['book_order'] == to_book_order)\n",
    "            ]['concept'])\n",
    "            to_earlier_set = set(df_master[\n",
    "                (df_master['series'] == to_series) &\n",
    "                (df_master['book_order'] < to_book_order)\n",
    "            ]['concept'])\n",
    "\n",
    "            repeated = from_set & to_book_set\n",
    "            new = to_book_set - from_set\n",
    "            missing = to_earlier_set - from_set\n",
    "\n",
    "            def get_weighted_total(concepts):\n",
    "                return sum(weights_dict.get(c, 0.25) for c in concepts)\n",
    "\n",
    "            total_weight = get_weighted_total(to_book_set) or 1.0\n",
    "            repeated_weighted = get_weighted_total(repeated)\n",
    "            new_weighted = get_weighted_total(new)\n",
    "            pct_repeated = round(repeated_weighted / total_weight * 100, 1) if total_weight else 0\n",
    "            pct_new = round(new_weighted / total_weight * 100, 1) if total_weight else 0\n",
    "\n",
    "            def sort_by_weight(concepts):\n",
    "                return sorted(concepts, key=lambda c: weights_dict.get(c, 0.25), reverse=True)\n",
    "\n",
    "            # Reading approach\n",
    "            from_approach = get_reading_approach(from_series, df_overview)\n",
    "            to_approach = get_reading_approach(to_series, df_overview)\n",
    "\n",
    "            results.append({\n",
    "                'From Series': from_series,\n",
    "                'From Book': row.get('From Book', ''),\n",
    "                'From Book Order': from_book,\n",
    "                'To Series': to_series,\n",
    "                'To Book': to_book_title,\n",
    "                'To Book Order': to_book_order,\n",
    "                'Pacing Label': row.get('Pacing Label', ''),\n",
    "                'Notes': row.get('Notes', ''),\n",
    "                '% New (Weighted)': pct_new,\n",
    "                '% Repeated (Weighted)': pct_repeated,\n",
    "                '# Missing': len(missing),\n",
    "                'New Concepts': \", \".join(sort_by_weight(new)),\n",
    "                'Repeated Concepts': \", \".join(sort_by_weight(repeated)),\n",
    "                'Missing Concepts': \", \".join(sort_by_weight(missing)),\n",
    "                'From Reading Approach': from_approach,\n",
    "                'To Reading Approach': to_approach\n",
    "            })\n",
    "\n",
    "        df_result = pd.DataFrame(results)\n",
    "        latest_df_result['df'] = df_result  # Store for download\n",
    "        display(df_result)\n",
    "\n",
    "        # Show download links\n",
    "        with download_output:\n",
    "            clear_output()\n",
    "            # CSV\n",
    "            df_result.to_csv(\"transition_analysis.csv\", index=False)\n",
    "            # Excel\n",
    "            df_result.to_excel(\"transition_analysis.xlsx\", index=False)\n",
    "            # JSON\n",
    "            fields = [\n",
    "                'From Series', 'From Book', 'From Book Order', 'To Series', 'To Book', 'To Book Order',\n",
    "                'Pacing Label', 'Notes', '% New (Weighted)', '% Repeated (Weighted)', '# Missing',\n",
    "                'New Concepts', 'Repeated Concepts', 'Missing Concepts', 'From Reading Approach', 'To Reading Approach'\n",
    "            ]\n",
    "            records = df_result[fields].to_dict(orient='records')\n",
    "            with open(\"transition_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "            # JS variable\n",
    "            with open(\"transition_analysis.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"const transitionData = \")\n",
    "                json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "                 # Uncomment for semicolon, leave off for none\n",
    "            display(FileLink(\"transition_analysis.csv\"))\n",
    "            display(FileLink(\"transition_analysis.xlsx\"))\n",
    "            display(FileLink(\"transition_analysis.json\"))\n",
    "            display(FileLink(\"transition_analysis.js\"))\n",
    "\n",
    "# --- UI Layout ---\n",
    "run_button.on_click(run_transition_analysis)\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([transition_file, overview_file]),\n",
    "    run_button,\n",
    "    download_output,\n",
    "    output\n",
    "])\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027f102-4a74-4651-bc71-6b73d5fa172b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
